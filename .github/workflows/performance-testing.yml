name: Performance Testing

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main
  schedule:
    # Run performance tests daily at 3 AM UTC
    - cron: '0 3 * * *'

jobs:
  performance-benchmarks:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    strategy:
      matrix:
        node-version: [18, 20]
        test-suite:
          - component-performance
          - memory-leak-detection
          - bundle-size-analysis
          - real-world-performance

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Need full history for performance comparison

      - name: Setup Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'

      - name: Install dependencies
        run: |
          npm ci
          npm install -g clinic autocannon

      - name: Build project for performance testing
        run: |
          npm run build:production
          npm run build:modular

      - name: Setup performance testing environment
        run: |
          # Enable garbage collection for memory testing
          export NODE_OPTIONS="--expose-gc --max-old-space-size=4096"

          # Create performance test results directory
          mkdir -p performance-results

          # Install additional performance tools
          npm install -g lighthouse-ci puppeteer

      - name: Run Component Performance Benchmarks
        if: matrix.test-suite == 'component-performance'
        run: |
          echo "ðŸš€ Running component performance benchmarks..."
          npm run test:performance:components

          # Store results
          cp test-results/performance-*.json performance-results/
        env:
          NODE_OPTIONS: "--expose-gc --max-old-space-size=4096"

      - name: Run Memory Leak Detection
        if: matrix.test-suite == 'memory-leak-detection'
        run: |
          echo "ðŸ§  Running memory leak detection..."
          npm run test:performance:memory

          # Generate memory profiling report
          node scripts/memory-profiler.js > performance-results/memory-report.json
        env:
          NODE_OPTIONS: "--expose-gc --max-old-space-size=4096"

      - name: Run Bundle Size Analysis
        if: matrix.test-suite == 'bundle-size-analysis'
        run: |
          echo "ðŸ“¦ Analyzing bundle performance..."
          npm run bundle:budget:enforce

          # Generate bundle analysis report
          npm run bundle:analyze:performance > performance-results/bundle-analysis.json

          # Check for performance regressions
          node scripts/bundle-performance-check.js

      - name: Run Real-World Performance Tests
        if: matrix.test-suite == 'real-world-performance'
        run: |
          echo "ðŸŒ Running real-world performance scenarios..."

          # Start test server
          npm run build-storybook
          npx http-server storybook-static -p 8080 --silent &
          sleep 10

          # Run Lighthouse performance tests
          npm install -g @lhci/cli
          lhci autorun --config=lighthouserc.performance.js

          # Run load testing
          autocannon -c 10 -d 30 http://localhost:8080 > performance-results/load-test.json

      - name: Analyze Performance Results
        run: |
          echo "ðŸ“Š Analyzing performance results..."
          node scripts/analyze-performance-results.js performance-results/

          # Generate performance score
          PERF_SCORE=$(node scripts/calculate-performance-score.js)
          echo "Performance Score: $PERF_SCORE"
          echo "PERFORMANCE_SCORE=$PERF_SCORE" >> $GITHUB_ENV

      - name: Check Performance Thresholds
        run: |
          echo "ðŸŽ¯ Checking S-Tier performance thresholds..."

          # S-Tier requirements:
          # - Overall performance score â‰¥ 90
          # - No memory leaks
          # - Bundle size < 30KB
          # - Render time < 16ms

          VIOLATIONS=""

          if [ "$PERFORMANCE_SCORE" -lt 90 ]; then
            VIOLATIONS="$VIOLATIONS\nâŒ Performance score ($PERFORMANCE_SCORE) below S-Tier threshold (90)"
          fi

          # Check for memory leaks
          if grep -q "MEMORY_LEAK_DETECTED" performance-results/memory-report.json; then
            VIOLATIONS="$VIOLATIONS\nâŒ Memory leaks detected"
          fi

          # Check bundle size
          BUNDLE_SIZE=$(jq -r '.totalSize' performance-results/bundle-analysis.json)
          if [ "$BUNDLE_SIZE" -gt 30720 ]; then  # 30KB in bytes
            VIOLATIONS="$VIOLATIONS\nâŒ Bundle size ($BUNDLE_SIZE bytes) exceeds 30KB limit"
          fi

          if [ -n "$VIOLATIONS" ]; then
            echo -e "Performance violations detected:$VIOLATIONS"
            echo "PERFORMANCE_VIOLATIONS=$VIOLATIONS" >> $GITHUB_ENV
            exit 1
          else
            echo "âœ… All S-Tier performance thresholds met!"
          fi

      - name: Upload Performance Artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: performance-results-${{ matrix.test-suite }}-node${{ matrix.node-version }}
          path: |
            performance-results/
            .lighthouseci/
          retention-days: 30

      - name: Generate Performance Report
        run: |
          echo "ðŸ“‹ Generating performance report..."
          node scripts/generate-performance-report.js \
            --results performance-results/ \
            --output performance-report.md \
            --suite ${{ matrix.test-suite }} \
            --node-version ${{ matrix.node-version }}

      - name: Comment PR with Performance Results
        if: github.event_name == 'pull_request' && matrix.test-suite == 'component-performance'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            let report = '';
            try {
              report = fs.readFileSync('performance-report.md', 'utf8');
            } catch (error) {
              report = `## âš¡ Performance Test Results

              Performance testing completed for Node.js ${{ matrix.node-version }}.

              **Score**: ${process.env.PERFORMANCE_SCORE || 'N/A'}/100

              ${process.env.PERFORMANCE_VIOLATIONS ?
                `### âš ï¸ Performance Issues:\n${process.env.PERFORMANCE_VIOLATIONS}` :
                '### âœ… All performance thresholds met!'}

              [View detailed results](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})`;
            }

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: report
            });

  performance-regression-detection:
    needs: performance-benchmarks
    runs-on: ubuntu-latest
    if: always()

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Download Performance Artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: performance-results-*
          merge-multiple: true

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Detect Performance Regressions
        run: |
          echo "ðŸ” Detecting performance regressions..."
          node scripts/detect-performance-regressions.js \
            --current performance-results/ \
            --baseline main \
            --threshold 10 # 10% regression threshold

      - name: Generate Comprehensive Performance Report
        run: |
          echo "ðŸ“Š Generating comprehensive performance report..."
          node scripts/generate-comprehensive-report.js \
            --results performance-results/ \
            --output comprehensive-performance-report.md

      - name: Upload Comprehensive Report
        uses: actions/upload-artifact@v4
        with:
          name: comprehensive-performance-report
          path: comprehensive-performance-report.md
          retention-days: 90

      - name: Update Performance Badge
        if: github.ref == 'refs/heads/main'
        run: |
          # Calculate overall performance grade
          OVERALL_SCORE=$(node scripts/calculate-overall-score.js performance-results/)

          if [ "$OVERALL_SCORE" -ge 95 ]; then
            GRADE="S-Tier"
            COLOR="brightgreen"
          elif [ "$OVERALL_SCORE" -ge 90 ]; then
            GRADE="A"
            COLOR="green"
          elif [ "$OVERALL_SCORE" -ge 80 ]; then
            GRADE="B"
            COLOR="yellow"
          else
            GRADE="C"
            COLOR="orange"
          fi

          # Update badge (would integrate with shields.io or similar)
          echo "Performance Grade: $GRADE (Score: $OVERALL_SCORE)"

  memory-leak-monitoring:
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule'

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run Extended Memory Leak Tests
        run: |
          echo "ðŸ§  Running extended memory leak monitoring..."
          npm run test:memory:extended
        env:
          NODE_OPTIONS: "--expose-gc --max-old-space-size=8192"

      - name: Generate Memory Health Report
        run: |
          node scripts/generate-memory-health-report.js > memory-health-report.json

      - name: Check for Memory Issues
        run: |
          if jq -e '.memoryLeaksDetected > 0' memory-health-report.json; then
            echo "ðŸš¨ Memory leaks detected in scheduled monitoring!"

            # Create issue for memory leak
            ISSUE_BODY="## ðŸ§  Memory Leak Alert

            Automated memory leak detection has found potential issues:

            $(cat memory-health-report.json | jq -r '.summary')

            **Action Required:**
            - Review recent changes to components
            - Check for event listener cleanup
            - Verify timer/interval cleanup
            - Run local memory profiling

            **Report Details:**
            [View full memory health report](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})
            "

            echo "$ISSUE_BODY" > issue-body.md
            echo "MEMORY_LEAK_DETECTED=true" >> $GITHUB_ENV
          fi

      - name: Create Memory Leak Issue
        if: env.MEMORY_LEAK_DETECTED == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const issueBody = fs.readFileSync('issue-body.md', 'utf8');

            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: 'ðŸš¨ Memory Leak Detection Alert',
              body: issueBody,
              labels: ['performance', 'memory-leak', 'priority-high', 'automated']
            });

  performance-dashboard-update:
    needs: [performance-benchmarks, performance-regression-detection]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' && always()

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Download Performance Data
        uses: actions/download-artifact@v4
        with:
          pattern: performance-results-*
          merge-multiple: true

      - name: Update Performance Dashboard
        run: |
          echo "ðŸ“ˆ Updating performance dashboard..."

          # Generate dashboard data
          node scripts/generate-dashboard-data.js performance-results/ > dashboard-data.json

          # Update metrics (would typically push to a monitoring service)
          echo "Dashboard data generated:"
          cat dashboard-data.json

      - name: Store Performance History
        run: |
          # Store historical performance data for trend analysis
          mkdir -p .performance-history
          TIMESTAMP=$(date +%Y%m%d-%H%M%S)
          cp dashboard-data.json .performance-history/performance-$TIMESTAMP.json

          # Keep only last 30 days of data
          find .performance-history -name "performance-*.json" -mtime +30 -delete

      - name: Commit Performance History
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add .performance-history/
          git commit -m "ðŸ“Š Update performance history [skip ci]" || exit 0
          git push
